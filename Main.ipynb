{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e16a23-a139-4e75-bc6c-b0e5eceec3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f60ab9d-763b-46a0-b5c2-adbdc495dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True, num_workers = 2)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "66f5585e-fded-4e9a-9d7d-1c1b6dc6e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412e2c97-cf64-4851-9dd3-de07a7ded204",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "705125b2-6918-4b57-86e9-922d0b7b53b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ba625a5d-0e36-41ec-9d3d-25c06ff4bbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base class of a neural network\n",
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define convolutional layer\n",
    "        self.conv1 = nn.Conv2d(3, 12, 5) # 3 input channels, 12 feature maps, 5x5 size.\n",
    "        self.pool = nn.MaxPool2d(2,2) # 4 pixels and creates one pixel (12, 14, 14)\n",
    "        self.conv2 = nn.Conv2d(12, 24, 5) # (14 - 5) / 1 = 9 + 1 = 10; (24, 10, 10) -> (24, 5, 5)\n",
    "        self.fc1 = nn.Linear(24 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ab920a5f-bfaf-4754-8e11-367ca9432102",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNet()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.001, momentum= 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e279c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(50):\n",
    "    print(f\"Training epoch {epoch}...\")\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Loss: {running_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "20d303ba-b11e-4528-ba16-a762c3bc1e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'trained_net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e768ecdd-4752-44f8-b633-e393c3aa04af",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNet()\n",
    "net.load_state_dict(torch.load('trained_net.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e508909-0801-4c1d-9dd9-63de25b851ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "\n",
    "print(f\"Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b71d9a6-1e2b-4b9a-9b04-793a2b6b9a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform definition\n",
    "new_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Function to load an image\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = new_transform(image)\n",
    "    image = image.unsqueeze(0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "# Load all images from './assets/' directory\n",
    "image_paths = [os.path.join('./assets/', img) for img in os.listdir('./assets/') if img.endswith('.jpg')]\n",
    "\n",
    "# Process images\n",
    "net.eval()  # Switch to evaluation mode\n",
    "with torch.no_grad():  # No need to calculate gradients during evaluation\n",
    "    for image_path in image_paths:\n",
    "        image = load_image(image_path)\n",
    "        output = net(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        print(f\"Prediction for {image_path}: {class_names[predicted.item()]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
